{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../img/ICHEC_Logo.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 - Hello World\n",
    "- Write a parallel Python program using MPI that prints out the number of processes and the MPI rank of each process. \n",
    "  - Use 6 cores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Simple Message Exchange (general Python objects)\n",
    "- Write a program where 2 processes send and recieve a message between each other using `send` and `recv`.\n",
    "  - The message should be a dictionary with the key `'rank': myrank`, where myrank is the rank of the sending process. \n",
    "  - After recieving the message, each process should print out the rank of the process and the values in the recieved dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 - Simple Message Exchange (NumPy arrays)\n",
    "- Write a program where in each process a 100,000 element NumPy array is initialised to the rank of process. \n",
    "- Send and recieve the array (using `Send` and `Recv`).\n",
    "- After recieving, print out the rank of the process along with the first element of the recieved array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4 - Message Chain\n",
    "- Write a simple program where every MPI task sends data to the next one. Let **ntasks** be the number of the tasks, and **myid** the rank of the current task. Your program should work as follows:\n",
    "  - Every task with a rank less than ntasks-1 sends a message to task myid+1.\n",
    "For example, task 0 sends a message to task 1.\n",
    "  - The message content is an integer array where each element is initialized to myid.\n",
    "  - The sender prints out the number of elements it sends.\n",
    "  - All tasks with rank â‰¥ 1 receive messages.\n",
    "  - Each receiver prints out their myid, and the first element in the received array.\n",
    "\n",
    "- Implement the program described above using `Send` and `Recv`.\n",
    "\n",
    "- Implement again but use Sendrecv instead of `Send` and `Recv` when sending and receiving.\n",
    "\n",
    "- Can the code be simplified using `MPI.PROC_NULL`?\n",
    "  - Use 10 cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile message_chain.py\n",
    "\n",
    "from mpi4py import MPI\n",
    "import sys\n",
    "import numpy as np\n",
    "from numpy.random import randint, seed\n",
    "\n",
    "\"\"\"Insert MPI variables below\"\"\"\n",
    "###\n",
    "\n",
    "###\n",
    "\n",
    "if rank == 0:\n",
    "    t_start = MPI.Wtime()\n",
    "\n",
    "'''Matrix size inputted through the terminal'''\n",
    "numberRows = int( sys.argv[1])\n",
    "numberColumns = int( sys.argv[2])\n",
    "\n",
    "\"\"\"checks\"\"\"\n",
    "assert numberRows == numberColumns\n",
    "assert numberRows % (worldSize) == 0 #make sure it is divisible\n",
    "\n",
    "#Calculate the slice per worker\n",
    "if (worldSize == 1):\n",
    "    Slice = int(numberRows)\n",
    "else:\n",
    "    Slice = int(numberRows / (worldSize)) \n",
    "\n",
    "assert Slice >= 1\n",
    "\n",
    "\"\"\"Set Matrix\"\"\"\n",
    "# Set seed to ensure same matrices when comparing the different techniques.\n",
    "# Welcome to change how matrix is populated. \n",
    "seed(30) \n",
    "def populateMatrix():\n",
    "    p = randint(0,10,size=(numberRows,numberColumns))\n",
    "    return p\n",
    "\n",
    "\"\"\"Initialising matrix a\"\"\"  \n",
    "if rank == 0:\n",
    "    ###\n",
    "    a = populateMatrix()\n",
    "    recv_data = a\n",
    "    ###\n",
    "\n",
    "\"\"\"Distributing the work to the processes\"\"\"\n",
    "    # Rank 0 sends the slices to the other ranks, keeping the first slice for itself\n",
    "    for i in range(1, worldSize):\n",
    "        offset = i * Slice\n",
    "        row = recv_data[offset,:]\n",
    "    \n",
    "        \"\"\"send the value of the offset and the group of rows to each rank\"\"\"\n",
    "        ###\n",
    "\n",
    "        ###\n",
    "\n",
    "b = populateMatrix()\n",
    "\"\"\"Recieve the offset and group of rows from rank 0\"\"\"\n",
    "# Rank 0 doesn't recieve anything\n",
    "# Hint: Use comm.Send() for arrays of data\n",
    "\n",
    "if rank!= 0:\n",
    "    ###\n",
    "    # Remember for comm.Send() - need buffer\n",
    "    ###\n",
    "\n",
    "\"\"\"Calculation\"\"\"\n",
    "b = populateMatrix()\n",
    "solution_chunk = np.dot(recv_chunk,b)\n",
    "\n",
    "\"\"\"Send the chunks of solution back to rank 0\"\"\"\n",
    "# Hint: Use comm.Send() for arrays of data\n",
    "###\n",
    "\n",
    "###\n",
    "\n",
    "if rank == 0:  \n",
    "    # Stack solution chunk from rank 0\n",
    "    product_solution = np.vstack(solution_chunk)\n",
    "        \"\"\"Recieve the rest\"\"\"\n",
    "    for i in range(1, worldSize):\n",
    "        \"\"\"Remember for comm.Send() - need buffer\"\"\"\n",
    "        ###\n",
    "\n",
    "        ###\n",
    "        print (\"Received response from %d.\\n\" %(i))\n",
    "        solution = np.vstack((product_solution,buffer_sol_i))\n",
    "    \n",
    "    print (\"Result AxB.\\n\")\n",
    "    print (solution)\n",
    "    \n",
    "    print (\"Parallel send and recieves - Total Time:\", MPI.Wtime()-t_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5 - Non-blocking communication\n",
    "- Implement the message chain program used in exercise 4 using non-blocking communication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6 - Collective Operations\n",
    "- In this exercise you will use different routines for collective communication. Use the skeleton code to get started.\n",
    "  \n",
    "  \n",
    "A) First, write a program where rank 0 sends an array containing integers from 0 to 7 to all other ranks using collective communication. Use four cores.\n",
    "[Hint: Use broadcasting]\n",
    "\n",
    "- From these arrays create the initial arrays shown below.\n",
    "\n",
    "B)\n",
    "\n",
    "|        |  |  |  |  |  |  |  |  |\n",
    "|--------|--|--|--|--|--|--|--|--|\n",
    "|Task 0: | 0| 1| 2| 3| 4| 5| 6| 7|\n",
    "|Task 1: | 8| 9|10|11|12|13|14|15|\n",
    "|Task 2: |16|17|18|19|20|21|22|23|\n",
    "|Task 3: |24|25|26|27|28|29|30|31|\n",
    "\n",
    "\n",
    "- Each task should recieve a buffer for eight elements with each one initialised to -1. \n",
    "\n",
    "- Implement a program that sends and receives values from the data arrays to recieve buffers using single collective routines so that the recieve buffers will have the following values;\n",
    "\n",
    "C)\n",
    "\n",
    "|        |  |  |  |  |  |  |  |  |\n",
    "|--------|--|--|--|--|--|--|--|--|\n",
    "|Task 0: | 0| 1|-1|-1|-1|-1|-1|-1|\n",
    "|Task 1: | 2| 3|-1|-1|-1|-1|-1|-1|\n",
    "|Task 2: | 4| 5|-1|-1|-1|-1|-1|-1|\n",
    "|Task 3: | 6| 7|-1|-1|-1|-1|-1|-1|\n",
    "\n",
    "- [Hint: Use `comm.Scatter()`]\n",
    "\n",
    "D)\n",
    "\n",
    "|        |  |  |  |  |  |  |  |  |\n",
    "|--------|--|--|--|--|--|--|--|--|\n",
    "|Task 0: |-1|-1|-1|-1|-1|-1|-1|-1|\n",
    "|Task 1: | 0| 1| 8| 9|16|17|24|25|\n",
    "|Task 2: |-1|-1|-1|-1|-1|-1|-1|-1|\n",
    "|Task 3: |-1|-1|-1|-1|-1|-1|-1|-1|\n",
    "\n",
    "- [Hint: Use `comm.Gather()`]\n",
    "\n",
    "E)\n",
    "\n",
    "|        |  |  |  |  |  |  |  |  |\n",
    "|--------|--|--|--|--|--|--|--|--|\n",
    "|Task 0: | 8|10|12|14|16|18|20|22|\n",
    "|Task 1: |-1|-1|-1|-1|-1|-1|-1|-1|\n",
    "|Task 2: |40|42|44|46|48|50|52|54|\n",
    "|Task 3: |-1|-1|-1|-1|-1|-1|-1|-1|\n",
    "\n",
    "- [Hint: Create two communicators and use `comm.Reduce()`]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile collective_operations.py\n",
    "\n",
    "from mpi4py import MPI\n",
    "import numpy\n",
    "from sys import stdout\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()\n",
    "\n",
    "assert size == 4, 'Number of MPI tasks has to be 4.'\n",
    "\n",
    "if rank == 0:\n",
    "    print('A)Broadcast:')\n",
    "\n",
    "# TODO: create data vector at task 0 and send it to everyone else\n",
    "#       using collective communication\n",
    "if rank == 0:\n",
    "    data = ...\n",
    "else:\n",
    "    data = ...\n",
    "...\n",
    "print('  Task {0}: {1}'.format(rank, data))\n",
    "\n",
    "\n",
    "# Prepare data vectors ..\n",
    "data = ...  # TODO: create the data vectors\n",
    "# .. and receive buffers\n",
    "buff = numpy.full(8, -1, int)\n",
    "\n",
    "# ... wait for every rank to finish ...\n",
    "comm.barrier()\n",
    "if rank == 0:\n",
    "    print('')\n",
    "    print('-' * 32)\n",
    "    print('')\n",
    "    print('B) Initial Data vectors:')\n",
    "print('  Task {0}: {1}'.format(rank, data))\n",
    "comm.barrier()\n",
    "if rank == 0:\n",
    "    print('')\n",
    "    print('-' * 32)\n",
    "    print('')\n",
    "    print('C) Scatter:')\n",
    "\n",
    "# TODO: how to get the desired receive buffer using a single collective\n",
    "#       communication routine?\n",
    "...\n",
    "print('  Task {0}: {1}'.format(rank, buff))\n",
    "\n",
    "# ... wait for every rank to finish ...\n",
    "buff[:] = -1\n",
    "comm.barrier()\n",
    "if rank == 0:\n",
    "    print('')\n",
    "    print('-' * 32)\n",
    "    print('')\n",
    "    print('D) Gather:')\n",
    "\n",
    "# TODO: how to get the desired receive buffer using a single collective\n",
    "#       communication routine?\n",
    "\n",
    "...\n",
    "print('  Task {0}: {1}'.format(rank, buff))\n",
    "\n",
    "# ... wait for every rank to finish ...\n",
    "buff[:] = -1\n",
    "comm.barrier()\n",
    "if rank == 0:\n",
    "    print('')\n",
    "    print('e)')\n",
    "\n",
    "# TODO: how to get the desired receive buffer using a single collective\n",
    "#       communication routine?\n",
    "...\n",
    "print('  Task {0}: {1}'.format(rank, buff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7 - Matrix Multiplier\n",
    "\n",
    "- Write a MPI script that multiplies two matrices together. \n",
    "  1) Divide up the tasks using send and recieves.\n",
    "  2) Divide up the tasks using collective operations. \n",
    "- Start with the provided skeleton scripts. \n",
    "- Submit a job that multiplies two 4000 x 4000 size matrices, using 20 processes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile matrix_multiplier.py\n",
    "\n",
    "from mpi4py import MPI\n",
    "import sys\n",
    "import numpy as np\n",
    "from numpy.random import randint, seed\n",
    "\n",
    "\"\"\"Insert MPI variables below\"\"\"\n",
    "###\n",
    "\n",
    "###\n",
    "\n",
    "if rank == 0:\n",
    "    t_start = MPI.Wtime()\n",
    "\n",
    "\"\"\"Matrix size inputted through the terminal\"\"\"\n",
    "numberRows = int( sys.argv[1])\n",
    "numberColumns = int( sys.argv[2])\n",
    "\n",
    "\"\"\"checks\"\"\"\n",
    "assert numberRows == numberColumns\n",
    "assert numberRows % (worldSize) == 0\n",
    "\n",
    "#Calculate the slice per worker\n",
    "if (worldSize == 1):\n",
    "    Slice = int(numberRows)\n",
    "else:\n",
    "    Slice = int(numberRows / (worldSize)) \n",
    "    \n",
    "assert Slice >= 1\n",
    "\n",
    "\"\"\"Set Matrix\"\"\"\n",
    "# Set seed to ensure same matrices when comparing the different techniques.\n",
    "# Welcome to change how matrix is populated. \n",
    "seed(30)\n",
    "def populateMatrix():\n",
    "    p = randint(0,10,size=(numberRows,numberColumns))\n",
    "    return p\n",
    "\n",
    "\"\"\"Initialising matrix a\"\"\"  \n",
    "if rank == 0:\n",
    "    ###\n",
    "\n",
    "    ###\n",
    "else:\n",
    "    a = None\n",
    " \n",
    "\"\"\"Scatter matrix a from rank 0 to the other ranks\"\"\"\n",
    "###\n",
    "# recv_chunk = ...\n",
    "###\n",
    "\n",
    "\"\"\"Calculation\"\"\"\n",
    "b = populateMatrix()\n",
    "solution_chunk = np.dot(recvd_chunk, b)\n",
    "\n",
    "\"\"\"Gather all the solution chunks\"\"\"\n",
    "###\n",
    "\n",
    "###\n",
    "\n",
    "\"\"\"Print the solution\"\"\"\n",
    "if rank == 0: \n",
    "    print (\"Result AxB.\\n\")\n",
    "    ###\n",
    "\n",
    "    ###\n",
    "    print (\"Parallel collective operations - Total Time\", MPI.Wtime() - t_start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
